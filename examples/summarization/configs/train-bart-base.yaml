task:
  class: HugginfaceSeq2SeqTask
  mode: train
  src: src
  tgt: tgt
  maxlen: (1024,300)
  preprocessed: True
  tokenizer:
    class: HuggingfaceTokenizer
    tokenizer_name: facebook/bart-base
  dataloader:
    train:
      class: InMemoryDataLoader
      sampler:
        class: ShuffleSampler
        max_samples: 64
    valid:
      class: InMemoryDataLoader
      sampler:
        class: SequentialSampler
        max_samples: 128
    test:
      class: InMemoryDataLoader
      sampler:
        class: SequentialSampler
        max_samples: 128
  data:
    train:
      class: JsonDataset
      path: data/train.index.json
    valid:
      class: JsonDataset
      sort_samples: True
      path: data/val.index.json
    test:
      class: JsonDataset
      sort_samples: True
      path: data/test.index.json
  model:
    class: HuggingfaceBartModel
    pretrained_model: facebook/bart-base
  criterion:
    class: CrossEntropy
  trainer:
    class: Trainer
    optimizer:
      class: HuggingfaceAdamW
      lr:
        class: PolynomialDecayScheduler
        max_rate: 5e-5
        warmup_steps: 500
        total_steps: 15000
      clip_norm: 1.0
      weight_decay: 0.01
      no_decay: ["norm","bias"]
      eps: 1e-8
    max_steps: 15000
    assess_by: valid.criterion
    save_model_dir: checkpoints
  generator:
    class: SelfContainedGenerator
    num_beams: 5
    max_length: 300
    min_length: 100
    no_repeat_ngram_size: 3
    length_penalty: 2.0
    early_stopping: True
  evaluator:
    class: Evaluator
    metric:
      rouge:
        class: Rouge
        ngram: 1,2,l
env:
  device: cuda
  fp16: True
  no_warning: True
  no_progress_bar: True

